{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_img = hog(img, orientations=orient,\n",
    "                                pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32):\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    return np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    \"\"\"\n",
    "    YCbCr seperate the luminance and chrominance components of a scene\n",
    "    and use less bits for chrominance than luminace.\n",
    "    \"\"\"\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cars(img, ystart, ystop, scale, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RBG2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale)), np.int(imshape[1]/scale))\n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "    \n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1\n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    blocks_per_step = 2\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // blocks_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // blocks_per_step\n",
    "    \n",
    "    hog1 = get_hog_feature(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_feature(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_feature(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb * blocks_per_step\n",
    "            xpos = xb * blocks_per_step\n",
    "            \n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window]\n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window]\n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window]\n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "            \n",
    "            xleft = xpos * pix_per_cell\n",
    "            ytop = ypos * pix_per_cell\n",
    "            \n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (32, 32))\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "            \n",
    "            feature = X_scalar.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "            yield feature\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs_path, spatial_size, hist_bins,\n",
    "                     ystart, ystop, scale,\n",
    "                     orient, pix_per_cell, cell_per_block):\n",
    "    features = []\n",
    "    for img_path in imgs_path:\n",
    "        img = cv2.imread(img_path)\n",
    "        feature = find_cars(img, ystart, ystop, scale, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "        features.append(feature) \n",
    "    return features      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs_path, cspace, spatial_size, hist_bins, orient, pix_per_cell, cell_per_block, hog_channel):\n",
    "    features = []\n",
    "    for img_path in tqdm(imgs_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        if cspace != 'BGR':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            \n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        features.append(np.concatenate([hog_features, spatial_features, hist_features]))\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "spatial_size = (48, 48) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "hist_range = (0, 256)\n",
    "y_start = 400 # Min and max in y to search in slide_window()\n",
    "y_stop = 656\n",
    "scale = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car image size is 8792\n",
      "notcar image size is 8968\n"
     ]
    }
   ],
   "source": [
    "car_dir = 'D:\\\\Repo\\\\CarND-Vehicle-Detection\\\\vehicles\\\\vehicles'\n",
    "cars = []\n",
    "for directory, _, files in os.walk(car_dir):\n",
    "    for image in files:\n",
    "        if image.endswith('png'): cars.append(os.path.join(directory, image))\n",
    "    \n",
    "notcar_dir = 'D:\\\\Repo\\\\CarND-Vehicle-Detection\\\\non-vehicles'\n",
    "notcars = []\n",
    "for directory, _, files in os.walk(notcar_dir):\n",
    "    for image in files:\n",
    "        if image.endswith('png'): notcars.append(os.path.join(directory, image))\n",
    "            \n",
    "print('car image size is {}'.format(len(cars)))\n",
    "print('notcar image size is {}'.format(len(notcars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8792/8792 [00:58<00:00, 149.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8968/8968 [00:58<00:00, 153.35it/s]\n"
     ]
    }
   ],
   "source": [
    "car_features = extract_features(cars, spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                        cspace='YCrCb', hog_channel=0,\n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block)\n",
    "notcar_features = extract_features(notcars, spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                        cspace='YCrCb', hog_channel=0,\n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.45 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9848\n",
      "My SVC predicts:  [ 1.  1.  1.  1.  0.  1.  1.  1.  1.  0.]\n",
      "For these 10 labels:  [ 1.  1.  1.  1.  0.  1.  1.  1.  1.  0.]\n",
      "0.02206 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
